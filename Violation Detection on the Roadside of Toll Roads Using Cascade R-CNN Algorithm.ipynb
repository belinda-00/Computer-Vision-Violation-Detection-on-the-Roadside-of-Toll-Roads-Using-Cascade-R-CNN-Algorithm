{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install semua environtment yang dibutuhkan MMDetection pada google drive "
      ],
      "metadata": {
        "id": "JskXgoPCww7m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fJ8HQXwwbMt",
        "outputId": "29f377fd-52a8-482b-a8a5-80147bdb6dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U openmim\n",
        "!mim install mmcv-full==1.7.1"
      ],
      "metadata": {
        "id": "LUOIjJxtwkiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive\n",
        "%cd MyDrive\n",
        "%cd mmdetection\n",
        "!pip install -v -e ."
      ],
      "metadata": {
        "id": "V7viMXL4woi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "# Example output: 2.23.0"
      ],
      "metadata": {
        "id": "HXfdl1OVwpM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ISI config.py FILE UNTUK TRAIN"
      ],
      "metadata": {
        "id": "VdEZkE0vx4iB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the new config inherits the base configs to highlight the necessary modification\n",
        "_base_ = '/content/drive/MyDrive/mmdetection/configs/cascade_rcnn/cascade_rcnn_r50_caffe_fpn_1x_coco.py'\n",
        "\n",
        "# 1. dataset settings\n",
        "dataset_type = 'CocoDataset'\n",
        "classes = ('Melanggar', 'Tidak Melanggar')\n",
        "data = dict(\n",
        "    samples_per_gpu=2,\n",
        "    workers_per_gpu=2,\n",
        "    train=dict(\n",
        "        type='CocoDataset',\n",
        "        # explicitly add your class names to the field `classes`\n",
        "        classes=classes,\n",
        "        ann_file='/content/drive/MyDrive/TAB-20230108T025806Z-001/TAB/dataset-cascade/92_4_4/train/_annotations.coco.json',\n",
        "        img_prefix='/content/drive/MyDrive/TAB-20230108T025806Z-001/TAB/dataset-cascade/92_4_4/train'),\n",
        "    val=dict(\n",
        "        type='CocoDataset',\n",
        "        # explicitly add your class names to the field `classes`\n",
        "        classes=classes,\n",
        "        ann_file='/content/drive/MyDrive/TAB-20230108T025806Z-001/TAB/dataset-cascade/92_4_4/valid/_annotations.coco.json',\n",
        "        img_prefix='/content/drive/MyDrive/TAB-20230108T025806Z-001/TAB/dataset-cascade/92_4_4/valid'),\n",
        "    test=dict(\n",
        "        type='CocoDataset',\n",
        "        # explicitly add your class names to the field `classes`\n",
        "        classes=classes,\n",
        "        ann_file='/content/drive/MyDrive/TAB-20230108T025806Z-001/TAB/dataset-cascade/92_4_4/test/_annotations.coco.json',\n",
        "        img_prefix='/content/drive/MyDrive/TAB-20230108T025806Z-001/TAB/dataset-cascade/92_4_4/test'))\n",
        "\n",
        "# 2. model settings\n",
        "\n",
        "# explicitly over-write all the `num_classes` field from default 80 to 5.\n",
        "model = dict(\n",
        "    roi_head=dict(\n",
        "        bbox_head=[\n",
        "            dict(\n",
        "                type='Shared2FCBBoxHead',\n",
        "                # explicitly over-write all the `num_classes` field from default 80 to 5.\n",
        "                num_classes=2),\n",
        "            dict(\n",
        "                type='Shared2FCBBoxHead',\n",
        "                # explicitly over-write all the `num_classes` field from default 80 to 5.\n",
        "                num_classes=2),\n",
        "            dict(\n",
        "                type='Shared2FCBBoxHead',\n",
        "                # explicitly over-write all the `num_classes` field from default 80 to 5.\n",
        "                num_classes=2)],\n",
        "    ))\n"
      ],
      "metadata": {
        "id": "BYwLL1WXx3Vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Dataset"
      ],
      "metadata": {
        "id": "8p6sGRl_xV1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/mmdetection/tools/train.py /content/config.py"
      ],
      "metadata": {
        "id": "FPbo3ewJwsDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Isi config Cascade RCNN"
      ],
      "metadata": {
        "id": "jvr6Dbe-LTvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = dict(\n",
        "    type='CascadeRCNN',\n",
        "    backbone=dict(\n",
        "        type='ResNet',\n",
        "        depth=50,\n",
        "        num_stages=4,\n",
        "        out_indices=(0, 1, 2, 3),\n",
        "        frozen_stages=1,\n",
        "        norm_cfg=dict(type='BN', requires_grad=True),\n",
        "        norm_eval=True,\n",
        "        style='pytorch',\n",
        "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
        "    neck=dict(\n",
        "        type='FPN',\n",
        "        in_channels=[256, 512, 1024, 2048],\n",
        "        out_channels=256,\n",
        "        num_outs=5),\n",
        "    rpn_head=dict(\n",
        "        type='RPNHead',\n",
        "        in_channels=256,\n",
        "        feat_channels=256,\n",
        "        anchor_generator=dict(\n",
        "            type='AnchorGenerator',\n",
        "            scales=[8],\n",
        "            ratios=[0.5, 1.0, 2.0],\n",
        "            strides=[4, 8, 16, 32, 64]),\n",
        "        bbox_coder=dict(\n",
        "            type='DeltaXYWHBBoxCoder',\n",
        "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
        "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
        "        loss_bbox=dict(\n",
        "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
        "    roi_head=dict(\n",
        "        type='CascadeRoIHead',\n",
        "        num_stages=3,\n",
        "        stage_loss_weights=[1, 0.5, 0.25],\n",
        "        bbox_roi_extractor=dict(\n",
        "            type='SingleRoIExtractor',\n",
        "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
        "            out_channels=256,\n",
        "            featmap_strides=[4, 8, 16, 32]),\n",
        "        bbox_head=[\n",
        "            dict(type='Shared2FCBBoxHead', num_classes=2),\n",
        "            dict(type='Shared2FCBBoxHead', num_classes=2),\n",
        "            dict(type='Shared2FCBBoxHead', num_classes=2)\n",
        "        ]),\n",
        "    train_cfg=dict(\n",
        "        rpn=dict(\n",
        "            assigner=dict(\n",
        "                type='MaxIoUAssigner',\n",
        "                pos_iou_thr=0.7,\n",
        "                neg_iou_thr=0.3,\n",
        "                min_pos_iou=0.3,\n",
        "                match_low_quality=True,\n",
        "                ignore_iof_thr=-1),\n",
        "            sampler=dict(\n",
        "                type='RandomSampler',\n",
        "                num=256,\n",
        "                pos_fraction=0.5,\n",
        "                neg_pos_ub=-1,\n",
        "                add_gt_as_proposals=False),\n",
        "            allowed_border=0,\n",
        "            pos_weight=-1,\n",
        "            debug=False),\n",
        "        rpn_proposal=dict(\n",
        "            nms_pre=2000,\n",
        "            max_per_img=2000,\n",
        "            nms=dict(type='nms', iou_threshold=0.7),\n",
        "            min_bbox_size=0),\n",
        "        rcnn=[\n",
        "            dict(\n",
        "                assigner=dict(\n",
        "                    type='MaxIoUAssigner',\n",
        "                    pos_iou_thr=0.5,\n",
        "                    neg_iou_thr=0.5,\n",
        "                    min_pos_iou=0.5,\n",
        "                    match_low_quality=False,\n",
        "                    ignore_iof_thr=-1),\n",
        "                sampler=dict(\n",
        "                    type='RandomSampler',\n",
        "                    num=512,\n",
        "                    pos_fraction=0.25,\n",
        "                    neg_pos_ub=-1,\n",
        "                    add_gt_as_proposals=True),\n",
        "                pos_weight=-1,\n",
        "                debug=False),\n",
        "            dict(\n",
        "                assigner=dict(\n",
        "                    type='MaxIoUAssigner',\n",
        "                    pos_iou_thr=0.6,\n",
        "                    neg_iou_thr=0.6,\n",
        "                    min_pos_iou=0.6,\n",
        "                    match_low_quality=False,\n",
        "                    ignore_iof_thr=-1),\n",
        "                sampler=dict(\n",
        "                    type='RandomSampler',\n",
        "                    num=512,\n",
        "                    pos_fraction=0.25,\n",
        "                    neg_pos_ub=-1,\n",
        "                    add_gt_as_proposals=True),\n",
        "                pos_weight=-1,\n",
        "                debug=False),\n",
        "            dict(\n",
        "                assigner=dict(\n",
        "                    type='MaxIoUAssigner',\n",
        "                    pos_iou_thr=0.7,\n",
        "                    neg_iou_thr=0.7,\n",
        "                    min_pos_iou=0.7,\n",
        "                    match_low_quality=False,\n",
        "                    ignore_iof_thr=-1),\n",
        "                sampler=dict(\n",
        "                    type='RandomSampler',\n",
        "                    num=512,\n",
        "                    pos_fraction=0.25,\n",
        "                    neg_pos_ub=-1,\n",
        "                    add_gt_as_proposals=True),\n",
        "                pos_weight=-1,\n",
        "                debug=False)\n",
        "        ]),\n",
        "    test_cfg=dict(\n",
        "        rpn=dict(\n",
        "            nms_pre=1000,\n",
        "            max_per_img=1000,\n",
        "            nms=dict(type='nms', iou_threshold=0.7),\n",
        "            min_bbox_size=0),\n",
        "        rcnn=dict(\n",
        "            score_thr=0.05,\n",
        "            nms=dict(type='nms', iou_threshold=0.5),\n",
        "            max_per_img=100)))\n",
        "dataset_type = 'CocoDataset'\n",
        "data_root = 'data/coco/'\n",
        "img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations', with_bbox=True),\n",
        "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
        "    dict(type='RandomFlip', flip_ratio=0.5),\n",
        "    dict(\n",
        "        type='Normalize',\n",
        "        mean=[123.675, 116.28, 103.53],\n",
        "        std=[58.395, 57.12, 57.375],\n",
        "        to_rgb=True),\n",
        "    dict(type='Pad', size_divisor=32),\n",
        "    dict(type='DefaultFormatBundle'),\n",
        "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
        "]\n",
        "test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(\n",
        "        type='MultiScaleFlipAug',\n",
        "        img_scale=(1333, 800),\n",
        "        flip=False,\n",
        "        transforms=[\n",
        "            dict(type='Resize', keep_ratio=True),\n",
        "            dict(type='RandomFlip'),\n",
        "            dict(\n",
        "                type='Normalize',\n",
        "                mean=[123.675, 116.28, 103.53],\n",
        "                std=[58.395, 57.12, 57.375],\n",
        "                to_rgb=True),\n",
        "            dict(type='Pad', size_divisor=32),\n",
        "            dict(type='ImageToTensor', keys=['img']),\n",
        "            dict(type='Collect', keys=['img'])\n",
        "        ])\n",
        "]\n",
        "data = dict(\n",
        "    samples_per_gpu=2,\n",
        "    workers_per_gpu=2,\n",
        "    train=dict(\n",
        "        type='CocoDataset',\n",
        "        ann_file=\n",
        "        '/content/drive/MyDrive/TAB-20230108T025806Z-001/TAB/dataset-cascade/200_cascade_dataset/train/_annotations.coco.json',\n",
        "        img_prefix=\n",
        "        '/content/drive/MyDrive/TAB-20230108T025806Z-001/TAB/dataset-cascade/200_cascade_dataset/train',\n",
        "        pipeline=[\n",
        "            dict(type='LoadImageFromFile'),\n",
        "            dict(type='LoadAnnotations', with_bbox=True),\n",
        "            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
        "            dict(type='RandomFlip', flip_ratio=0.5),\n",
        "            dict(\n",
        "                type='Normalize',\n",
        "                mean=[123.675, 116.28, 103.53],\n",
        "                std=[58.395, 57.12, 57.375],\n",
        "                to_rgb=True),\n",
        "            dict(type='Pad', size_divisor=32),\n",
        "            dict(type='DefaultFormatBundle'),\n",
        "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
        "        ],\n",
        "        classes=('Melanggar', 'Tidak Melanggar')),\n",
        "    val=dict(\n",
        "        type='CocoDataset',\n",
        "        ann_file=\n",
        "        '/content/drive/MyDrive/TAB-20230108T025806Z-001/TAB/dataset-cascade/200_cascade_dataset/valid/_annotations.coco.json',\n",
        "        img_prefix=\n",
        "        '/content/drive/MyDrive/TAB-20230108T025806Z-001/TAB/dataset-cascade/200_cascade_dataset/valid',\n",
        "        pipeline=[\n",
        "            dict(type='LoadImageFromFile'),\n",
        "            dict(\n",
        "                type='MultiScaleFlipAug',\n",
        "                img_scale=(1333, 800),\n",
        "                flip=False,\n",
        "                transforms=[\n",
        "                    dict(type='Resize', keep_ratio=True),\n",
        "                    dict(type='RandomFlip'),\n",
        "                    dict(\n",
        "                        type='Normalize',\n",
        "                        mean=[123.675, 116.28, 103.53],\n",
        "                        std=[58.395, 57.12, 57.375],\n",
        "                        to_rgb=True),\n",
        "                    dict(type='Pad', size_divisor=32),\n",
        "                    dict(type='ImageToTensor', keys=['img']),\n",
        "                    dict(type='Collect', keys=['img'])\n",
        "                ])\n",
        "        ],\n",
        "        classes=('Melanggar', 'Tidak Melanggar')),\n",
        "    test=dict(\n",
        "        type='CocoDataset',\n",
        "        ann_file=\n",
        "        '/content/drive/MyDrive/TAB-20230108T025806Z-001/TAB/dataset-cascade/200_cascade_dataset/test/_annotations.coco.json',\n",
        "        img_prefix=\n",
        "        '/content/drive/MyDrive/TAB-20230108T025806Z-001/TAB/dataset-cascade/200_cascade_dataset/test',\n",
        "        pipeline=[\n",
        "            dict(type='LoadImageFromFile'),\n",
        "            dict(\n",
        "                type='MultiScaleFlipAug',\n",
        "                img_scale=(1333, 800),\n",
        "                flip=False,\n",
        "                transforms=[\n",
        "                    dict(type='Resize', keep_ratio=True),\n",
        "                    dict(type='RandomFlip'),\n",
        "                    dict(\n",
        "                        type='Normalize',\n",
        "                        mean=[123.675, 116.28, 103.53],\n",
        "                        std=[58.395, 57.12, 57.375],\n",
        "                        to_rgb=True),\n",
        "                    dict(type='Pad', size_divisor=32),\n",
        "                    dict(type='ImageToTensor', keys=['img']),\n",
        "                    dict(type='Collect', keys=['img'])\n",
        "                ])\n",
        "        ],\n",
        "        classes=('Melanggar', 'Tidak Melanggar')))\n",
        "evaluation = dict(interval=1, metric='bbox')\n",
        "optimizer = dict(type='SGD', lr=0.0001, momentum=0.9, weight_decay=0.0001)\n",
        "optimizer_config = dict(grad_clip=None)\n",
        "lr_config = dict(\n",
        "    policy='step',\n",
        "    warmup='linear',\n",
        "    warmup_iters=500,\n",
        "    warmup_ratio=0.001,\n",
        "    step=[8, 11])\n",
        "runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
        "checkpoint_config = dict(interval=1)\n",
        "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
        "custom_hooks = [dict(type='NumClassCheckHook')]\n",
        "dist_params = dict(backend='nccl')\n",
        "log_level = 'INFO'\n",
        "load_from = None\n",
        "resume_from = None\n",
        "workflow = [('train', 1)]\n",
        "opencv_num_threads = 0\n",
        "mp_start_method = 'fork'\n",
        "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
        "classes = ('Melanggar', 'Tidak Melanggar')\n",
        "work_dir = './work_dirs/200Dataset_lr_nolkomaempatnolsatu'\n",
        "auto_resume = False\n",
        "gpu_ids = [0]\n"
      ],
      "metadata": {
        "id": "pm-2u0w4K-OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inferensi Deteksi Pelanggaran Pada gambar"
      ],
      "metadata": {
        "id": "MDLsZu8vLjJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mmdet.apis import init_detector, inference_detector\n",
        "import mmcv\n",
        "\n",
        "# Specify the path to model config and checkpoint file\n",
        "config_file = 'configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'\n",
        "checkpoint_file = 'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
        "\n",
        "# build the model from a config file and a checkpoint file\n",
        "model = init_detector(config_file, checkpoint_file, device='cuda:0')\n",
        "\n",
        "# test a single image and show the results\n",
        "img = 'test.jpg'  # or img = mmcv.imread(img), which will only load it once\n",
        "result = inference_detector(model, img)\n",
        "# visualize the results in a new window\n",
        "model.show_result(img, result)\n",
        "# or save the visualization results to image files\n",
        "model.show_result(img, result, out_file='result.jpg')\n"
      ],
      "metadata": {
        "id": "CLCceblpLhKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference Dengan Video"
      ],
      "metadata": {
        "id": "pGVigIfXL5Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python demo/video_demo.py demo/demo.mp4 \\\n",
        "    configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py \\\n",
        "    checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \\\n",
        "    --out result.mp4"
      ],
      "metadata": {
        "id": "nyRyyDoGL38M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OJSvr646wvh_"
      }
    }
  ]
}